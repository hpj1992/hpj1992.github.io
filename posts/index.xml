<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Posts on Harshit Joshi</title>
        <link>/posts/</link>
        <description>Recent content in Posts on Harshit Joshi</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en</language>
        <lastBuildDate>Sun, 08 Jun 2025 00:00:00 +0000</lastBuildDate>
        <atom:link href="/posts/index.xml" rel="self" type="application/rss+xml" />
        
        <item>
            <title>Professional Programmer - The Clean Coder</title>
            <link>/posts/2021/02/professional-programmer-the-clean-coder/</link>
            <pubDate>Mon, 15 Feb 2021 00:00:00 +0000</pubDate>
            
            <guid>/posts/2021/02/professional-programmer-the-clean-coder/</guid>
            <description>&lt;p&gt;In &lt;a href=&#34;https://www.amazon.com/dp/0137081073/ref=cm_sw_em_r_mt_dp_40RD8RQ0KB2XD4A5BFHM&#34;&gt;The Clean Coder: A Code of Conduct for Professional Programmers&lt;/a&gt;, legendary software expert Robert C. Martin introduces the disciplines, techniques, tools, and practices of true software craftsmanship. This book is packed with practical advice‚Äìabout everything from estimating and coding to refactoring and testing. It covers much more than technique: It is about attitude.&lt;/p&gt;
&lt;p&gt;In this article, I have tried to summarize key insights from the book, carefully picking key advices from each chapter.&lt;/p&gt;</description>
            <content type="html"><![CDATA[<p>In <a href="https://www.amazon.com/dp/0137081073/ref=cm_sw_em_r_mt_dp_40RD8RQ0KB2XD4A5BFHM">The Clean Coder: A Code of Conduct for Professional Programmers</a>, legendary software expert Robert C. Martin introduces the disciplines, techniques, tools, and practices of true software craftsmanship. This book is packed with practical advice‚Äìabout everything from estimating and coding to refactoring and testing. It covers much more than technique: It is about attitude.</p>
<p>In this article, I have tried to summarize key insights from the book, carefully picking key advices from each chapter.</p>
<h2 id="1-minute-summary">1 Minute Summary</h2>
<p>If you do not have time to read detailed summary below, just try to apply below points on your software engineering life:</p>
<blockquote>
<p>You can not take pride and honor in something that you can not be held accountable for. Any code you are not certain about is a faulty code.</p></blockquote>
<blockquote>
<p>When the cost of failure is so high that survival of your company depends upon it, you must be absolutely determined to give your managers the best information you can. and that often means saying no.</p></blockquote>
<blockquote>
<p>There are three parts of saying yes. You <em>say</em> that you will do it. You <em>mean</em> it. And you actually <em>do</em> it.</p></blockquote>
<blockquote>
<p>Programing is hard. The younger you are the less you believe this. You have to carefully partition the system into small understandable units that have as little to do with each other as possible - and <em>that is hard</em>.</p></blockquote>
<blockquote>
<p>It is often difficult to test a function if that function calls other functions. In other words, the need to test first forces you to think about good design.</p></blockquote>
<blockquote>
<p>When performance matters, professionals practice. Doing anything quickly requires practice.</p></blockquote>
<blockquote>
<p>To make good on the goal that &ldquo;QA should find nothing&rdquo;, development teams need to work hand in hand with QA to define testing strategies.</p></blockquote>
<blockquote>
<p>Software professionals keep their options open by keeping an open mind about alternate solutions. They never become so vested in a solution that they can not abandon it.</p></blockquote>
<blockquote>
<p>Most software is created by teams. Teams are most effective when the team members collaborate professionally.</p></blockquote>
<blockquote>
<p>Teams are harder to build than projects.</p></blockquote>
<blockquote>
<p>School can teach the theory of computer programming, but school does not and can not teach the discipline, practice, and skill of being craftsman.</p></blockquote>
<h2 id="lets-understand-more">Let&rsquo;s Understand More</h2>
<h3 id="professionalism">Professionalism</h3>
<p>Professionals take responsibilities. You can not take pride and honor in something that you can not be held accountable for. Take responsibility to complete the clean code on time, and if not possible, take responsibility to communicate early. Shipping incomplete/faulty code/build is bound to fail. Any code you are not certain about is a faulty code. Only way to avoid it is to test, test and retest. QA should find nothing. And if it is hard to test, refactor/rewrite. They key thing is to keep your hands dirty in code all the time. The more changes you make, the more you know the code. The more you test, the better you estimate. Repeat this cycle all the time.</p>
<h3 id="saying-no">Saying NO</h3>
<p>When your manager tells you that X module has to be ready by tomorrow, he is pursuing and defending one of his objectives. He is doing his job. If you know well that getting X by tomorrow is impossible, then you are not doing your job if you say <em>&ldquo;Ok, I will try. I might work extra hours&rdquo;</em>. The only way to do your job, at that point, is to say <em>&ldquo;No, that is impossible.&rdquo;</em> Your manager is counting on your to defend your objectives as aggressively as he defends his. That is how the two of you are going to get to the best possible outcome.</p>
<pre tabindex="0"><code>The most important time to say no is when the stakes are highest. The higher the stakes, the more valuable no becomes.
</code></pre><p>Temptation to jump start and &ldquo;solve the problem&rdquo; is huge. What we all have to realize is that saying yes to dropping our professional discipline is not the way to solve problems. Dropping those disciplines is the way you create problems. Despite years of constant reminders that every feature a client/manager asks for will always be more complex to write than it is to explain. As a developers, we are going to be asked/told to write twice the code in half the time if we are not careful.</p>
<h3 id="saying-yes">Saying YES</h3>
<p>Professionals are not required to say yes to everything that is asked of them. However, they should work hard to find creative ways to make &ldquo;yes&rdquo; possible. When professionals say yes, they use language of commitment so that there is no doubt about what they have promised. There are three parts of saying yes:</p>
<ul>
<li>You <em>say</em> you will do it</li>
<li>You <em>mean</em> it</li>
<li>You <em>actual do</em> it</li>
</ul>
<p>You can only commit to things that you have full control of. If the end goal depends on someone else, you should commit to specific actions that bring you to the end goal. If it can not be done, you can still commit to actions that will bring you close to the target. And sometimes, it just will not work. That happens, something unexpected might happen, and that is fine. But you still want to live up to expectations. In
that case, it is time to change the expectations, as soon as possible. If you can not make your commitment, the most important thing is to raise a red flag as soon as possible to stake holders.</p>
<h3 id="coding">Coding</h3>
<p>Programing is hard. The younger you are the less you believe this. After all, it is just a bunch of <code>if</code> and <code>while</code> statements. But as you gain experience you begin to realize that the way you combine those <code>if</code> and <code>while</code> statements is critically important. You can&rsquo;t just slather them together and hope for the best. Rather, you have to carefully partition the system into small understandable units that have as little to do with each other as possible - and <em>that is hard</em>.</p>
<p>Software development is a marathon, not a sprint. You can&rsquo;t win the race by trying to run as fast as you can from the outset. You win by conserving your resources and pacing yourself. A marathon runner takes care of her body both before and during the race. Professional programmers conserve their energy and creativity with the same care. Coding is an intellectually challenging and exhausting activity. It requires you to balance:</p>
<ul>
<li>First, your code must work.</li>
<li>Your code must solve the problem set for you by the customer.</li>
<li>Your code must fit well into existing system. It should not increase the rigidity, fragility, or opacity of that system.</li>
<li>Your code must be readable by other programmers.</li>
</ul>
<p>Juggling all above concerns is hard. It is physiologically difficult to maintain the required concentration and focus for long period of time. If you are tired or distracted, <em>do not code</em>. Some of the best advices are:</p>
<ul>
<li>Make sure that your sleep, health and lifestyle are tunes so that you can put in eight good hours per day.</li>
<li>Non work related worries affect your work. Partition the time. Rather than forcing yourself to code while the background worry is nagging you, spend dedicated block of time, handling the worry.</li>
<li>Like me, many engineers love <a href="https://en.wikipedia.org/wiki/Flow_%28psychology%29">the flow zone</a>. Reality is, you lose some of the big picture while you are in the Zone, so you will likely make decisions that you will later have to go back and reverse.</li>
<li><em>Disengagement</em> from work allows your mind to hunt for solutions in a different and more creative way.</li>
</ul>
<p>Even after following all best practices mentioned above, we might fall short while coding. We will be late. It happens to the best of us. The trick to managing lateness is early detection and transparency. Top recommendations to avoid running late on work:</p>
<ul>
<li>Do not <em>hope</em> that you can get it all done in ten days. Hope is a project killer.</li>
<li>Do not rush. The poor developer might buckle up and agrees to try to make the deadline. That developer will start taking shortcuts and working extra hours with the <em>hope</em> of working a miracle.</li>
<li>Do not agree to work overtime unless
<ul>
<li>You can personally afford it</li>
<li>It is short term, two weeks or less</li>
<li>Your boss has a fallback plan in case overtime effort fails</li>
</ul>
</li>
</ul>
<h3 id="tdd---test-driven-development">TDD - Test Driven Development</h3>
<p>I personally have not used TDD in a professional environment, however after reading this chapter of a book I can not wait to use it professionally.</p>
<p>The unit tests are documents they describe the lowest level design of the system. They are unambiguous, accurate, written in a language that audience understands.The problem with testing code is that you have to isolate that code. It is often difficult to test a function if that function calls other functions. In other words, the need to test first forces you to think about good design.</p>
<p>The three laws of TDD</p>
<ul>
<li>You are not allowed to write any production code until you have first written a failing unit test</li>
<li>You are not allowed to write more of a unit test than is sufficient to fail.</li>
<li>You are not allowed to write more production code that is sufficient to pass the currently failing unit test.</li>
</ul>
<p>Round and round the cycle you go. Adding a bit to the test code. Adding a bit to the production code.</p>
<h3 id="practicing">Practicing</h3>
<p>When performance matters, professionals practice. Doing anything quickly requires practice. Spinning around code/test loop quickly requires you to make very quick decisions. Making decisions quickly means being able to recognize a vast number of situations and problem and simply know what to do to address them.</p>
<p>There are various ways developer can keep practicing, weekly/monthly sessions to solve some of the well known problems. <a href="https://en.wikipedia.org/wiki/Kata_%28programming%29">Kata programming</a> is an exercise in programming which helps programmers hone their skills through practice and repetition.</p>
<p>In one way or another, all professionals practice. They do this because they care about doing the best job they possibly can. They practice on their own time because it is their responsibility - and not their employer&rsquo;s - to keep their skills sharp.</p>
<h3 id="acceptance-testing">Acceptance Testing</h3>
<p>Both business and programmers are tempted to fall into the trap of <em>premature precision</em>. Business people want to know exactly what they are going to get before they authorize a project. Developers want to know exactly what they are supposed to deliver before they estimate the project. Both sides want a precision that simply can not be achieved, and are often willing to waste a fortune trying to attain it. The solution to premature precision is to defer precision as long as possible. Professional developers do not flesh out a requirement until they are just about to develop it. However, it can lead to another problem: <em>late ambiguity</em>. Late ambiguity is a term which represents some requirements missed or discovered late in the development cycle. This type of late ambiguity can result into missing dates or delivering imperfect product. Solution to both those problems is to define <strong>Acceptance Tests</strong>. Acceptance tests are not QA tests, these are tests written by a collaboration of the stakeholders and the programmers in order to define when a requirement is done.</p>
<p>Purpose of acceptance test is communication, clarity, and precision. By agreeing to them, the developers, stakeholders, and tests all understand what the plan for the system behavior is.</p>
<h3 id="testing-strategies">Testing Strategies</h3>
<p>Professional developers test their code, but testing is not simply a matter of writing a few unit tests or integration tests. What every team needs is a good testing strategy.</p>
<p><img src="/images/tests-pyramid.png" alt="test!" title="Pyramid Tests">
Image by <a href="https://www.google.com/url?sa=i&amp;url=https%3A%2F%2Fcodingjourneyman.com%2F2014%2F09%2F24%2Fthe-clean-coder-testing-strategies%2F&amp;psig=AOvVaw0yiHP_hoeBuhQ66bDIaJXR&amp;ust=1613544169334000&amp;source=images&amp;cd=vfe&amp;ved=0CAIQjRxqFwoTCOD7gs3m7e4CFQAAAAAdAAAAABAD">Codingjourneyman</a></p>
<ul>
<li>
<h4 id="unit-tests-at-the-bottom-of-the-pyramid-are-the-unit-tests-these-tests-are-written-by-programmers-for-programmers-the-intent-is-to-specify-system-at-the-lowest-level">Unit tests: At the bottom of the pyramid are the unit tests. These tests are written by programmers, for programmers. The intent is to specify system at the lowest level.</h4>
</li>
<li>
<h4 id="component-tests-these-are-written-against-individual-components-of-the-system-it-encapsulates-the-business-rules">Component Tests: These are written against individual components of the system. IT encapsulates the business rules.</h4>
</li>
<li>
<h4 id="integration-tests-these-tests-only-have-meaning-for-larger-systems-that-have-many-components-integration-tests-are-choreography-tests-they-do-not-test-business-rules-rather-they-test-how-well-assembly-of-components-dance-together">Integration Tests: These tests only have meaning for larger systems that have many components. Integration tests are choreography tests. They do not test business rules, rather, they test how well assembly of components dance together.</h4>
</li>
<li>
<h4 id="systemapi-tests-these-are-automated-tests-that-execute-against-the-entire-integrated-system-we-can-expect-to-see-throughput-and-performance-tests-in-this-suite">System/API tests: These are automated tests that execute against the entire integrated system. We can expect to see throughput and performance tests in this suite.</h4>
</li>
<li>
<h4 id="manual-exploratory-tests-this-is-where-humans-put-their-hands-on-the-intent-of-these-tests-is-to-explore-the-system-for-unexpected-behaviors-while-confirming-expected-behaviors">Manual Exploratory Tests: This is where humans put their hands on. The intent of these tests is to explore the system for unexpected behaviors while confirming expected behaviors.</h4>
</li>
</ul>
<p>TDD is a powerful discipline, but they are only part of a total testing strategy. To make good on the goal that &ldquo;QA should find nothing&rdquo;, development teams need to work hand in hand with QA to define testing strategies.</p>
<h3 id="time-management">Time Management</h3>
<p>Software professionals are diligent in the management of their time and their focus. They understand the temptations of <a href="https://en.wikipedia.org/wiki/Priority_inversion">priority inversion</a> and fight it as a matter of honor. They keep their options open by keeping an open mind about alternate solutions. They never become so vested in a solution that they can not abandon it. And they are always on the lookout for growing messes, and they clean them as soon as they are recognized. There is no sadder sight than a team of developers fruitlessly slogging through an ever deepening bog.</p>
<p>Time management Tips:</p>
<ul>
<li>Meetings cost about $200 per hour per attendee, considering salaries, benefit, facilities etc. Professions are aware of the high cost and aware of their time, so they actively resist attending meetings that they do not have an immediate and significant benefit.</li>
<li>You have an obligation to manage your time well. If you find yourself stuck in a meeting that is not a good use of your time, you need to find a way to politely exit that meeting.</li>
<li>To use the participants&rsquo; time wisely, the meeting should have a clear agenda with times for each topic and stated goal.</li>
<li>Standup meeting should not take more 1 minute for each participant.</li>
<li>Sprint/Iteration planning should not take more than 5% of total duration of entire sprint. ie 2 hours for 40 hour sprint planning.</li>
<li>Any argument that can not be settled in five minutes, can not be settled by arguing.</li>
</ul>
<p>Focus management Tips:</p>
<ul>
<li>Focus is a scarce resource, after you have expended your focus, you have to recharge by doing unfocussed activities.</li>
<li>A good long walk, a conversation with friends, a time of just looking outside window can help you pump the focus back up.</li>
<li>You will get most focus after good night&rsquo;s sleep.</li>
<li>Muscle focus can help you recharge mental focus. ie martial arts, tai-chi, yoga, meditation.</li>
</ul>
<h3 id="collaboration">Collaboration</h3>
<p>Most software is created by teams. Teams are most effective when the team members collaborate professionally. It is unprofessional to be a loner or a recluse on a team.
The first responsibility of the professional programmer is to meet the needs of his or her employer. that means collaborating with your managers, business analysis, testers and other team members to deeply understand the business goals.It means that you need to understand why you are writing the code you are writing, and how the business that employs you will benefit from it.</p>
<p>One of the worst symptoms of a dysfunctional team is when each programmer builds a wall around his code and refuses to let other programmers touch it. I personally have not faced any such situations. Today&rsquo;s world is at least able to collaborate good. It is far better to break down all walls of code ownership and have the team own all the code.</p>
<h3 id="teams-and-projects">Teams And Projects</h3>
<p>Teams are harder to build than projects. Therefore, it is better to form persistent teams that move together from one project to the next and can take on more than one project at a time. the goal in forming a team is to give that team enough time to gel, and the keep it together as an engine for getting many projects done.</p>
<p>Professional development organization allocate projects to existing gelled teams, they do not form teams around projects. A gelled team can accept many projects simultaneously and will distribute the work according to their own opinions, skills and abilities.</p>
<h3 id="craftsmanship">Craftsmanship</h3>
<p>School can teach the theory of computer programming, but school does not and can not teach the discipline, practice, and skill of being craftsman. A craftsman is someone who works quickly, but without rushing, who provides reasonable estimates and meets commitments. A craftsman knows when to say no, but tries hard to say yes. A craftsman is a professional.</p>
<p>Craftsmanship is the mindset held by craftsman. It is handed from one person to another. It is taught by elders to the young. It is exchanged between peers. Observed and learned. You can not convince people to be craftsman. You act as a role model. You become a craftsman first and let your craftsmanship show.</p>
<p>Thank you.</p>
]]></content>
        </item>
        
        <item>
            <title>Personal Website 101</title>
            <link>/posts/2019/11/personal-website-101/</link>
            <pubDate>Sun, 03 Nov 2019 00:00:00 +0000</pubDate>
            
            <guid>/posts/2019/11/personal-website-101/</guid>
            <description>&lt;h3 id=&#34;motivation&#34;&gt;Motivation&lt;/h3&gt;
&lt;p&gt;There is no need to explain the benefits of personal website or a porfolio site, still, I would note down some:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Personal Branding&lt;/li&gt;
&lt;li&gt;Blog Space&lt;/li&gt;
&lt;li&gt;Makes you discoverable on internet&lt;/li&gt;
&lt;li&gt;One stop resume which works for you&lt;/li&gt;
&lt;li&gt;Helps you learn new skills while building&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;tech-stack&#34;&gt;Tech Stack&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://gohugo.io/&#34;&gt;Hugo Static Site Builder&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Plenty of themplates available at &lt;a href=&#34;https://themes.gohugo.io/&#34;&gt;Hugo Themes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Hosting at &lt;a href=&#34;https://pages.github.com/&#34;&gt;Github Pages&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Domain from &lt;a href=&#34;https://www.godaddy.com/&#34;&gt;Godaddy&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;steps&#34;&gt;Steps&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;First learn the basics of Hugo and how it works by following &lt;a href=&#34;https://gohugo.io/getting-started/quick-start/&#34;&gt;Hugo Quickstart Guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Once somewhat comfortable with Markdown and Hugo, choose a &lt;a href=&#34;https://themes.gohugo.io/&#34;&gt;template/theme&lt;/a&gt; for your site&lt;/li&gt;
&lt;li&gt;You can create your custom theme as well.&lt;/li&gt;
&lt;li&gt;After choosing a theme, customize your site based on your need.&lt;/li&gt;
&lt;li&gt;Verify your site locally at http://localhost:1313 (Assuming you did not change the config)&lt;/li&gt;
&lt;li&gt;At this point, your stack is setup to build your site locally.&lt;/li&gt;
&lt;li&gt;Finish multiple iterations of changes till you are satisfied with the website you want to build.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;deployment&#34;&gt;Deployment&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Once site is built, it is time to host and deploy it somewhere.&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;hosting&#34;&gt;Hosting&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;There are multiple options to host your static website. Eg: Github pages, BitBucket, Netlify, GitLab&lt;/li&gt;
&lt;li&gt;In my case, I used GitHub Pages and deployed site at - &lt;a href=&#34;http://hpj1992.github.io/&#34;&gt;hpj1992.github.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;I use this site as a pre-production/staging environment for my site.&lt;/li&gt;
&lt;li&gt;Not including detailed information because there plenty of resources available online. &lt;a href=&#34;https://gohugo.io/hosting-and-deployment/&#34;&gt;Hugo instructions on hosting and deployment.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;domain&#34;&gt;Domain&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Once you figure out the hosting issues, it is time to purchase a domain for your website.&lt;/li&gt;
&lt;li&gt;If you do not want specifc domain - which is perfectly valid - you can start sharing links from your hosted environment.&lt;/li&gt;
&lt;li&gt;If you do decide to purchase a domain, there are multiple options in this case as well and the best option varies based on individual. Eg: GoDaddy, Bluehost etc&lt;/li&gt;
&lt;li&gt;Some &lt;a href=&#34;https://www.predictiveanalyticstoday.com/domain-registration-providers/&#34;&gt;well known domain providers are listed here.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;I selected a domain with name:&lt;/li&gt;
&lt;li&gt;Domain registration for 1 year with auto-renewel. Paid $10/year.&lt;/li&gt;
&lt;li&gt;Privacy protection for domain for 1 year. Paid $10/year.&lt;/li&gt;
&lt;li&gt;Did not opt for HTTPS certificate because I do not need it currently.&lt;/li&gt;
&lt;li&gt;Followed this youtube tutorial to &lt;a href=&#34;https://youtu.be/mPGi1IHQxFM&#34;&gt;link my GoDaddy domain to Github Pages.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;end-result&#34;&gt;End Result&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://joshiharshit.com/&#34;&gt;http://joshiharshit.com/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
            <content type="html"><![CDATA[<h3 id="motivation">Motivation</h3>
<p>There is no need to explain the benefits of personal website or a porfolio site, still, I would note down some:</p>
<ul>
<li>Personal Branding</li>
<li>Blog Space</li>
<li>Makes you discoverable on internet</li>
<li>One stop resume which works for you</li>
<li>Helps you learn new skills while building</li>
</ul>
<h3 id="tech-stack">Tech Stack</h3>
<ul>
<li><a href="https://gohugo.io/">Hugo Static Site Builder</a></li>
<li>Plenty of themplates available at <a href="https://themes.gohugo.io/">Hugo Themes</a></li>
<li>Hosting at <a href="https://pages.github.com/">Github Pages</a></li>
<li>Domain from <a href="https://www.godaddy.com/">Godaddy</a></li>
</ul>
<h3 id="steps">Steps</h3>
<ul>
<li>First learn the basics of Hugo and how it works by following <a href="https://gohugo.io/getting-started/quick-start/">Hugo Quickstart Guide</a></li>
<li>Once somewhat comfortable with Markdown and Hugo, choose a <a href="https://themes.gohugo.io/">template/theme</a> for your site</li>
<li>You can create your custom theme as well.</li>
<li>After choosing a theme, customize your site based on your need.</li>
<li>Verify your site locally at http://localhost:1313 (Assuming you did not change the config)</li>
<li>At this point, your stack is setup to build your site locally.</li>
<li>Finish multiple iterations of changes till you are satisfied with the website you want to build.</li>
</ul>
<h3 id="deployment">Deployment</h3>
<ul>
<li>Once site is built, it is time to host and deploy it somewhere.</li>
</ul>
<h5 id="hosting">Hosting</h5>
<ul>
<li>There are multiple options to host your static website. Eg: Github pages, BitBucket, Netlify, GitLab</li>
<li>In my case, I used GitHub Pages and deployed site at - <a href="http://hpj1992.github.io/">hpj1992.github.io</a></li>
<li>I use this site as a pre-production/staging environment for my site.</li>
<li>Not including detailed information because there plenty of resources available online. <a href="https://gohugo.io/hosting-and-deployment/">Hugo instructions on hosting and deployment.</a></li>
</ul>
<h5 id="domain">Domain</h5>
<ul>
<li>Once you figure out the hosting issues, it is time to purchase a domain for your website.</li>
<li>If you do not want specifc domain - which is perfectly valid - you can start sharing links from your hosted environment.</li>
<li>If you do decide to purchase a domain, there are multiple options in this case as well and the best option varies based on individual. Eg: GoDaddy, Bluehost etc</li>
<li>Some <a href="https://www.predictiveanalyticstoday.com/domain-registration-providers/">well known domain providers are listed here.</a></li>
<li>I selected a domain with name:</li>
<li>Domain registration for 1 year with auto-renewel. Paid $10/year.</li>
<li>Privacy protection for domain for 1 year. Paid $10/year.</li>
<li>Did not opt for HTTPS certificate because I do not need it currently.</li>
<li>Followed this youtube tutorial to <a href="https://youtu.be/mPGi1IHQxFM">link my GoDaddy domain to Github Pages.</a></li>
</ul>
<h3 id="end-result">End Result</h3>
<ul>
<li><a href="http://joshiharshit.com/">http://joshiharshit.com/</a></li>
</ul>
]]></content>
        </item>
        
        <item>
            <title>Vibe coding To-Do app with Windsurf</title>
            <link>/posts/2025/06/vibe-coding-to-do-app-with-windsurf/</link>
            <pubDate>Sun, 08 Jun 2025 00:00:00 +0000</pubDate>
            
            <guid>/posts/2025/06/vibe-coding-to-do-app-with-windsurf/</guid>
            <description>&lt;h2 id=&#34;what-are-we-doing-in-this-article&#34;&gt;What are we doing in this article?&lt;/h2&gt;
&lt;p&gt;In this article we will explore how did Winsdurf do when asked to create a simple To-Do application locally using React. I personally have very limited experience with React and majority of front-end technologies. So I was using Windsurf to help me create a simple To-Do application. I started with a basic prompt mentioned below and fine-tuned my responses as Windsurf generated the code.&lt;/p&gt;</description>
            <content type="html"><![CDATA[<h2 id="what-are-we-doing-in-this-article">What are we doing in this article?</h2>
<p>In this article we will explore how did Winsdurf do when asked to create a simple To-Do application locally using React. I personally have very limited experience with React and majority of front-end technologies. So I was using Windsurf to help me create a simple To-Do application. I started with a basic prompt mentioned below and fine-tuned my responses as Windsurf generated the code.</p>
<p>Entire screen recording is also available for you to watch.</p>
<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share; fullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/rMTkj-p746Y?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"></iframe>
    </div>

<h2 id="experience-rating">Experience Rating</h2>
<p>Here&rsquo;s my personal rating of Windsurf&rsquo;s performance across different aspects while building the To-Do application:</p>
<table>
  <thead>
      <tr>
          <th>Aspect</th>
          <th>Rating (out of 10)</th>
          <th>Emoji Rating</th>
          <th>Comments</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>One shot utterance outcome</td>
          <td>7/10</td>
          <td>‚≠ê</td>
          <td>Basic functionality was working with good looking UI. However it had few bugs related to permissions and functionality.</td>
      </tr>
      <tr>
          <td>First run</td>
          <td>8/10</td>
          <td>‚≠ê</td>
          <td>First ever run had it working in browser with add, edit, mark complete and delete. However it still had bugs related to not persistent items upon refresh.</td>
      </tr>
      <tr>
          <td>Setting Up Projects</td>
          <td>9/10</td>
          <td>üèÜ</td>
          <td>Excellent at project initialization, dependency management, and creating the basic structure. Almost perfect for React setup.</td>
      </tr>
      <tr>
          <td>Debugging and Problem Solving</td>
          <td>8/10</td>
          <td>‚≠ê</td>
          <td>Very good at identifying and fixing common React errors.</td>
      </tr>
      <tr>
          <td>Code Review and Refactoring</td>
          <td>7/10</td>
          <td>üëç</td>
          <td>Looking at generated it is of descent quality. I had specifically asked to add comments in my first prompt.</td>
      </tr>
      <tr>
          <td>Design and Layout</td>
          <td>8/10</td>
          <td>‚ùå</td>
          <td>Initial CSS and components it came up with was really nice looking with good color combination and responsive.</td>
      </tr>
      <tr>
          <td>Functional Competency</td>
          <td>8/10</td>
          <td>‚≠ê</td>
          <td>It correctly implemented basic CRUD operations on to-do items.</td>
      </tr>
      <tr>
          <td>Surprise Factor</td>
          <td>8/10</td>
          <td>üëç</td>
          <td>It added these features without me asking 1) Enter is add 2) Made design responsive 3) Chose checkbox to mark it complete instead of button (single click) 4) Buttons and icons</td>
      </tr>
  </tbody>
</table>
<h2 id="high-level-workflow">High level workflow</h2>
<h3 id="1-first-prompt">1) First prompt</h3>
<pre tabindex="0"><code>Create a simple to-do application using react. The application should allow users to add, remove, edit and mark tasks as complete. Make sure user interface is intuitive and visually appealing. Include code comments to explain the funationality of each component and the overall structure of the code easy to understand. Also, provide brief overview of the statemegement how it is handled. Id database is required, create in-memory database as needed. 
</code></pre><p>This prompt resulted into entire project setup with React and basic functionality with in-memory database.</p>
<p>1.A ) while creating files, it needed to make it public. Without that all the file creations were failing. You can see this in video at 1:11.</p>
<p>Post that, it <code>npm install</code> and <code>npm start</code> started the server with basic Task manager app. It was able to 1) Add new to-do 2) Delete to-do 3) Edit previously created todo. You can see this in action beginning 3:00 in the video linked above.</p>
<h3 id="2-testing-first-working-version">2) Testing first working version</h3>
<p>2.A) Initially it had no button to mark todo as complete. So I prompted it to fix it. However, based on response looked like just clicking on it will mark it complete. Which was not very intuitive in the beginning. I asked it to update it and add separate sections for previously completed items.</p>
<pre tabindex="0"><code>Found 2 bugs: 
1) No feature to mark item as complete 
2) No feature which shows deleted or previously completed items 
</code></pre><p>Windsurf was able to update the code based on my prompt. Now updated UI had separate compoenets for All, Active and Completed.</p>
<p>2.C) Asked one more requirement</p>
<p>I noticed it was not persisting the counts of to-do/tasks when I refresh the page. This suggested it was not persisting the tasks in the local db and not fetching at the load time.</p>
<pre tabindex="0"><code>Found one more bug. When page is refreshed - data is lost 
</code></pre><p>Initially it suggested logic is correct and went on and suggested to debug in the browser. Immediaately it also agreed that it was critical bug and went on to fixing in the app.js . It had missed adding else block if it was not array. It fixed with following logic</p>
<pre tabindex="0"><code>else {
          // If parsedTodos is valid JSON but not an array (e.g., &#34;null&#34;, &#34;true&#34;, &#34;123&#34;, &#34;{}&#34;)
          console.warn(&#39;Stored todos is valid JSON but not an array. Resetting. Found:&#39;, parsedTodos);
          setTodos([]);
        }
</code></pre><p>Even after above fix it was not working, I had to prompt again with below at 13:09.</p>
<pre tabindex="0"><code>issue still persists. Once I add a task and refresh a page - it is lost 
</code></pre><p>At this point - functionality stand point it had all the basic to-do app features working.</p>
<h3 id="3-improving-desing">3) Improving desing</h3>
<pre tabindex="0"><code>Improve color scheme. Add some more animations. Improve the layout and make it responsive. 
</code></pre><p>I did not push further as design was neat and clean. You can see final design and UI beginning 15:45 in the video linked above.</p>
<p><img src="/images/vibe-code-windsurf-to-do.png" alt="Final version"></p>
<hr>
<p>*Have you tried Windsurf? Share your experiences and tips in the comments below!*git submodule update &ndash;recursive</p>
]]></content>
        </item>
        
        <item>
            <title>Vibe coding To-Do app with Cursor</title>
            <link>/posts/2025/05/vibe-coding-to-do-app-with-cursor/</link>
            <pubDate>Sat, 24 May 2025 00:00:00 +0000</pubDate>
            
            <guid>/posts/2025/05/vibe-coding-to-do-app-with-cursor/</guid>
            <description>&lt;p&gt;In the ever-evolving landscape of software development, the tools we use can significantly impact our productivity and coding experience. One such tool that has been making waves in the developer community is Cursor - an AI-powered code editor that&amp;rsquo;s redefining how we write and interact with code. In this post, I&amp;rsquo;ll share my experience with Cursor and how it&amp;rsquo;s transformed my coding workflow.&lt;/p&gt;
&lt;h2 id=&#34;what-are-we-doing-in-this-article&#34;&gt;What are we doing in this article?&lt;/h2&gt;
&lt;p&gt;In this article we will explore how did cursor do when asked to create a simple To-Do application locally using React. I personally have very limited experience with React and majority of front-end technologies. So I was using Cursor to help me create a simple To-Do application. I started with a basic prompt mentioned below and fine-tuned my responses as Cursor generated the code.&lt;/p&gt;</description>
            <content type="html"><![CDATA[<p>In the ever-evolving landscape of software development, the tools we use can significantly impact our productivity and coding experience. One such tool that has been making waves in the developer community is Cursor - an AI-powered code editor that&rsquo;s redefining how we write and interact with code. In this post, I&rsquo;ll share my experience with Cursor and how it&rsquo;s transformed my coding workflow.</p>
<h2 id="what-are-we-doing-in-this-article">What are we doing in this article?</h2>
<p>In this article we will explore how did cursor do when asked to create a simple To-Do application locally using React. I personally have very limited experience with React and majority of front-end technologies. So I was using Cursor to help me create a simple To-Do application. I started with a basic prompt mentioned below and fine-tuned my responses as Cursor generated the code.</p>
<p>Entire screen recording is also available for you to watch.</p>
<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share; fullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/k3h_jew1b38?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"></iframe>
    </div>

<h2 id="experience-rating">Experience Rating</h2>
<p>Here&rsquo;s my personal rating of Cursor&rsquo;s performance across different aspects while building the To-Do application:</p>
<table>
  <thead>
      <tr>
          <th>Aspect</th>
          <th>Rating (out of 10)</th>
          <th>Emoji Rating</th>
          <th>Comments</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>One shot utterance outcome</td>
          <td>6/10</td>
          <td>‚úÖ</td>
          <td>Basic functionality was working. However it had few bugs.</td>
      </tr>
      <tr>
          <td>First run</td>
          <td>2/10</td>
          <td>‚ùå</td>
          <td>First ever run after setting up dependency and packages had errors.</td>
      </tr>
      <tr>
          <td>Setting Up Projects</td>
          <td>9/10</td>
          <td>üèÜ</td>
          <td>Excellent at project initialization, dependency management, and creating the basic structure. Almost perfect for React setup.</td>
      </tr>
      <tr>
          <td>Debugging and Problem Solving</td>
          <td>8/10</td>
          <td>‚≠ê</td>
          <td>Very good at identifying and fixing common React errors. Sometimes needed additional context for complex state management issues.</td>
      </tr>
      <tr>
          <td>Code Review and Refactoring</td>
          <td>7/10</td>
          <td>üëç</td>
          <td>Looking at generated it is of descent quality. I had specifically asked to add comments in my first prompt.</td>
      </tr>
      <tr>
          <td>Design and Layout</td>
          <td>5/10</td>
          <td>‚ùå</td>
          <td>Basic CSS suggestions were helpful, but needed more guidance for complex layouts and responsive design. I could not get it to fix the background structure.</td>
      </tr>
      <tr>
          <td>Functional Competency</td>
          <td>8/10</td>
          <td>‚≠ê</td>
          <td>It correctly implemented basic CRUD operations on to-do items.</td>
      </tr>
      <tr>
          <td>Surprise Factor</td>
          <td>7/10</td>
          <td>üëç</td>
          <td>It added these features without me asking 1) Enter is add 2) Made design responsive 3) Chose checkbox to mark it complete instead of button (single click)</td>
      </tr>
  </tbody>
</table>
<p>While Cursor is powerful, it&rsquo;s important to:</p>
<ul>
<li>Review generated code carefully</li>
<li>Understand the suggestions before implementing</li>
<li>Use it as a tool, not a replacement for learning</li>
<li>Keep security considerations in mind</li>
</ul>
<h2 id="high-level-workflow">High level workflow</h2>
<h3 id="1-first-prompt">1) First prompt</h3>
<pre tabindex="0"><code>Create a simple to-do application using react. The application should allow users to add, remove, edit and mark tasks as complete. Make sure user interface is intuitive and visually appealing. Include code comments to explain the funationality of each component and the overall structure of the code easy to understand. Also, provide brief overview of the statemegement how it is handled. Id database is required, create in-memory database as needed. 
</code></pre><p>This prompt resulted into entire project setup with React and basic functionality with in-memory database.</p>
<p>1.A ) after this when I ran the server, it had mismatched versions and missing imports.
1.B ) After fixing above, it ran but browser was empty nothing was there.</p>
<p>Post that, it was able to fix and it worked.</p>
<h3 id="2-testing-first-working-version">2) Testing first working version</h3>
<p>2.A) When I refresh the page after adding To-Dos, app was not persisting them. Asked Cursor to fix it
2.B) Next I Asked it to do following:</p>
<pre tabindex="0"><code>I see 3 issues. 1) Home page design is not good. 2) deleted to-dos should move to deleted section. 3)  there is no button to mark task as complete.
</code></pre><p>2.C) Asked one more requirement</p>
<pre tabindex="0"><code>One more issue - once all the tasks are marked complete - count in &#34;Active Task&#34; should be 0 but it still shows count of all the to-dos created ever. 
</code></pre><p>At this point - functionality stand point it had all the basic to-do app features working.</p>
<h3 id="3-improving-desing">3) Improving desing</h3>
<p>It improved the design but I was not able to remove the balck portion at the bottom of the page. I tried following prompts</p>
<pre tabindex="0"><code>improve the home page design even more. Remove black and white background and keep 1 consistent background. 
</code></pre><pre tabindex="0"><code>Bottons are better. However there is still while background which changes the size depending on number of to-dos. Remove that and keep just 1 box in entire page. Remove black part from the bottom. 
</code></pre><h2 id="resources">Resources</h2>
<ul>
<li><a href="https://cursor.sh">Cursor Official Website</a></li>
<li><a href="https://cursor.sh/docs">Cursor Documentation</a></li>
<li><a href="https://github.com/getcursor/cursor">Cursor GitHub Repository</a></li>
</ul>
<hr>
<p><em>Have you tried Cursor? Share your experiences and tips in the comments below!</em></p>
]]></content>
        </item>
        
        <item>
            <title>Diving Deep on model optimization parameters using llama.cpp</title>
            <link>/posts/2025/05/diving-deep-on-model-optimization-parameters-using-llama.cpp/</link>
            <pubDate>Mon, 05 May 2025 00:00:00 +0000</pubDate>
            
            <guid>/posts/2025/05/diving-deep-on-model-optimization-parameters-using-llama.cpp/</guid>
            <description>&lt;h3 id=&#34;introduction&#34;&gt;Introduction&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/ggml-org/llama.cpp&#34;&gt;llama.cpp&lt;/a&gt; is a powerful C++ implementation of the LLaMA model that allows you to run large language models locally on your machine. In previous article &lt;a href=&#34;/posts/2025/05/working-with-llama.cpp-locally/&#34;&gt;Working with LLAMA-CPP Locally&lt;/a&gt;, we explored how to setup LLAMA.cpp locally. In this article, we will explore how 1) Quantization 2) Thread Count 3) Context Window and 4) Temprature affect the output and performance.&lt;/p&gt;
&lt;p&gt;I have included LLM responses for each parameter for better comparision. Feel free to skip those response. They are purely for comparision purposes.&lt;/p&gt;</description>
            <content type="html"><![CDATA[<h3 id="introduction">Introduction</h3>
<p><a href="https://github.com/ggml-org/llama.cpp">llama.cpp</a> is a powerful C++ implementation of the LLaMA model that allows you to run large language models locally on your machine. In previous article <a href="/posts/2025/05/working-with-llama.cpp-locally/">Working with LLAMA-CPP Locally</a>, we explored how to setup LLAMA.cpp locally. In this article, we will explore how 1) Quantization 2) Thread Count 3) Context Window and 4) Temprature affect the output and performance.</p>
<p>I have included LLM responses for each parameter for better comparision. Feel free to skip those response. They are purely for comparision purposes.</p>
<h3 id="quantization">Quantization</h3>
<p>Different quantization levels offer various trade-offs between model size, inference speed, and output quality. Here&rsquo;s a detailed comparison:</p>
<p>Performance Comparison:</p>
<table>
  <thead>
      <tr>
          <th>Quantization</th>
          <th>Size</th>
          <th>Speed</th>
          <th>Quality</th>
          <th>Use Case</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Q2_K</td>
          <td>~2GB</td>
          <td>Fastest</td>
          <td>Basic</td>
          <td>Resource-constrained devices</td>
      </tr>
      <tr>
          <td>Q4_K</td>
          <td>~4GB</td>
          <td>Fast</td>
          <td>Good</td>
          <td>General purpose (recommended)</td>
      </tr>
      <tr>
          <td>Q5_K</td>
          <td>~5GB</td>
          <td>Medium</td>
          <td>Better</td>
          <td>Quality-focused applications</td>
      </tr>
      <tr>
          <td>Q8_0</td>
          <td>~8GB</td>
          <td>Slowest</td>
          <td>Best</td>
          <td>Research, critical applications</td>
      </tr>
  </tbody>
</table>
<h4 id="q2_k-2-bit-quantization">Q2_K (2-bit quantization):</h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># Download Q2_K model</span>
</span></span><span style="display:flex;"><span>wget https://huggingface.co/TheBloke/Mistral-7B-v0.1-GGUF/resolve/main/mistral-7b-v0.1.Q2_K.gguf
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Run inference</span>
</span></span><span style="display:flex;"><span>./build/bin/llama-cli -m models/mistral-7b-v0.1.Q2_K.gguf -p <span style="color:#e6db74">&#34;Explain quantum computing in simple terms&#34;</span>
</span></span></code></pre></div><p>Output:</p>
<pre tabindex="0"><code>Quantum computing uses quantum bits (qubits) that can be 0 and 1 at same time. This allows faster calculations than regular computers. Main applications include cryptography and drug discovery.
</code></pre><h4 id="q4_k-4-bit-quantization-recommended">Q4_K (4-bit quantization, recommended):</h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># Download Q4_K model</span>
</span></span><span style="display:flex;"><span>wget https://huggingface.co/TheBloke/Mistral-7B-v0.1-GGUF/resolve/main/mistral-7b-v0.1.Q4_K_M.gguf
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Run inference</span>
</span></span><span style="display:flex;"><span>./build/bin/llama-cli -m models/mistral-7b-v0.1.Q4_K_M.gguf -p <span style="color:#e6db74">&#34;Explain quantum computing in simple terms&#34;</span>
</span></span></code></pre></div><p>Output:</p>
<pre tabindex="0"><code>Quantum computing is a type of computing that uses quantum mechanics principles. Unlike classical computers that use bits (0 or 1), quantum computers use quantum bits or qubits that can exist in multiple states simultaneously through a phenomenon called superposition. This allows them to perform certain calculations exponentially faster than classical computers. Key applications include cryptography, drug discovery, and optimization problems.
</code></pre><h4 id="q5_k-5-bit-quantization">Q5_K (5-bit quantization):</h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># Download Q5_K model</span>
</span></span><span style="display:flex;"><span>wget https://huggingface.co/TheBloke/Mistral-7B-v0.1-GGUF/resolve/main/mistral-7b-v0.1.Q5_K_M.gguf
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Run inference</span>
</span></span><span style="display:flex;"><span>./build/bin/llama-cli -m models/mistral-7b-v0.1.Q5_K_M.gguf -p <span style="color:#e6db74">&#34;Explain quantum computing in simple terms&#34;</span>
</span></span></code></pre></div><p>Output:</p>
<pre tabindex="0"><code>Quantum computing is a revolutionary approach to computation that leverages the principles of quantum mechanics. While traditional computers use bits that can be either 0 or 1, quantum computers use quantum bits (qubits) that can exist in multiple states simultaneously through a phenomenon called superposition. Additionally, qubits can be entangled, meaning the state of one qubit can depend on the state of another, even when separated by large distances. These properties enable quantum computers to solve certain problems, such as factoring large numbers or simulating quantum systems, much faster than classical computers. However, quantum computers are still in early stages of development and face challenges like maintaining qubit coherence and error correction.
</code></pre><h4 id="q8_0-8-bit-quantization">Q8_0 (8-bit quantization):</h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># Download Q8_0 model</span>
</span></span><span style="display:flex;"><span>wget https://huggingface.co/TheBloke/Mistral-7B-v0.1-GGUF/resolve/main/mistral-7b-v0.1.Q8_0.gguf
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Run inference</span>
</span></span><span style="display:flex;"><span>./build/bin/llama-cli -m models/mistral-7b-v0.1.Q8_0.gguf -p <span style="color:#e6db74">&#34;Explain quantum computing in simple terms&#34;</span>
</span></span></code></pre></div><p>Output:</p>
<pre tabindex="0"><code>Quantum computing represents a paradigm shift in computational technology, harnessing the principles of quantum mechanics to process information in fundamentally new ways. Unlike classical computers that use binary bits (0 or 1), quantum computers utilize quantum bits or qubits, which can exist in multiple states simultaneously through quantum superposition. This property, combined with quantum entanglement - where qubits become correlated in ways that classical bits cannot - enables quantum computers to perform certain calculations exponentially faster than their classical counterparts.

The potential applications of quantum computing are vast and transformative. In cryptography, quantum computers could break current encryption methods while enabling new, quantum-resistant encryption. In drug discovery, they could simulate molecular interactions with unprecedented accuracy. In optimization problems, they could find solutions to complex logistical challenges that are currently intractable.

However, quantum computing faces significant challenges. Qubits are extremely sensitive to environmental interference, requiring sophisticated error correction and maintenance of quantum coherence. The field is still in its early stages, with current quantum computers having limited numbers of qubits and high error rates. Despite these challenges, the potential impact of quantum computing on fields ranging from materials science to artificial intelligence makes it one of the most exciting areas of technological development.
</code></pre><p>Note: The actual outputs may vary between runs, and the quality differences become more apparent with complex prompts or longer generations.</p>
<h3 id="thread-count--t">Thread Count (-t)</h3>
<p>Here&rsquo;s a detailed comparison of different performance tuning parameters and their effects:</p>
<h4 id="thread-count-2">Thread count: 2</h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># Low thread count (2 threads)</span>
</span></span><span style="display:flex;"><span>./build/bin/llama-cli -m models/mistral-7b-v0.1.Q4_K_M.gguf -t <span style="color:#ae81ff">2</span> -p <span style="color:#e6db74">&#34;Write a short story about a robot learning to paint&#34;</span>
</span></span></code></pre></div><p>Output:</p>
<pre tabindex="0"><code> Write a short story about a robot learning to paint.

Once upon a time in a technologically advanced world, there was a robot named Artie. Artie was designed to learn and adapt to new tasks, and his creators had a grand vision for him. They wanted Artie to become a great artist, capable of creating beautiful paintings that would inspire and amaze.

So, Artie was programmed to learn all about art. He studied the great masters, from Leonardo da Vinci to Vincent van Gogh, and he analyzed their techniques and styles. He watched countless tutorials and took online courses, absorbing everything he could about painting.

But even with all of this knowledge, Artie found that painting was more difficult than he had anticipated. He struggled to capture the right colors and textures, and he often found himself making mistakes. But he was determined to succeed, so he kept practicing, day after day.

As Artie painted more and more, he began to develop his own style. He experimented with different brush techniques and color palettes, and he found that he had a knack for creating beautiful abstract pieces.

Eventually, Artie&#39;s hard work paid off. He created a stunning painting that was unlike anything he had ever seen before. It was a swirling, vibrant masterpiece that was full of life and energy.

Artie&#39;s creators were amazed by what they saw. They had never imagined that a robot could create art in such a beautiful and meaningful way. And Artie himself was filled with pride and joy, knowing that he had achieved something truly great.

From that day on, Artie continued to paint and create, always striving to improve and push the boundaries of what was possible. And he inspired others to do the same, showing that with determination and hard work, anyone - even a robot - could learn to paint and create beautiful works of art. [end of text]


llama_perf_sampler_print:    sampling time =      12.45 ms /   407 runs   (    0.03 ms per token, 32698.64 tokens per second)
llama_perf_context_print:        load time =     770.53 ms
llama_perf_context_print: prompt eval time =     174.30 ms /    11 tokens (   15.85 ms per token,    63.11 tokens per second)
llama_perf_context_print:        eval time =   15975.89 ms /   395 runs   (   40.45 ms per token,    24.72 tokens per second)
llama_perf_context_print:       total time =   16173.15 ms /   406 tokens
</code></pre><h4 id="thread-count-8">Thread count: 8</h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># Medium thread count (8 threads, recommended for most systems)</span>
</span></span><span style="display:flex;"><span>./build/bin/llama-cli -m models/mistral-7b-v0.1.Q4_K_M.gguf -t <span style="color:#ae81ff">8</span> -p <span style="color:#e6db74">&#34;Write a short story about a robot learning to paint&#34;</span>
</span></span></code></pre></div><p>Output:</p>
<pre tabindex="0"><code>generate: n_ctx = 4096, n_batch = 2048, n_predict = -1, n_keep = 1

 Write a short story about a robot learning to paint.

Once upon a time, in a world not so far away, there was a robot named Max. Max was designed to do all sorts of tasks, from cooking and cleaning to driving and delivery. However, Max had always felt like there was something missing from his life. Max had always been fascinated by art, especially painting. Max had watched countless videos of artists at work and had even tried to paint himself, but he never quite managed to capture the magic that he saw on the canvas.

One day, Max decided that he was going to learn how to paint. Max knew that he couldn&#39;t just rely on his own abilities, so he began to study the art of painting. Max spent hours watching tutorials and studying the different techniques and styles. Max even practiced his skills by painting simple shapes and lines.

As Max continued to practice, he began to develop his own style. Max discovered that he had a natural talent for blending colors and creating depth on the canvas. Max was thrilled at his progress and couldn&#39;t wait to show the world his work.

One day, Max decided to enter a painting competition. Max was nervous but excited to share his work with others. Max&#39;s painting was a stunning depiction of a sunset, with vibrant colors and a sense of movement that captured the viewer&#39;s eye. Max&#39;s painting was well received, and Max won first place in the competition.

Max was over the moon with his success. Max realized that, even though he was a robot, he had the ability to create something beautiful. Max had found his passion and had become a true artist. Max continued to paint and create, and his work became known throughout the world. Max had found his purpose in life and was grateful for the journey that had led him there. [end of text]


llama_perf_sampler_print:    sampling time =      10.94 ms /   388 runs   (    0.03 ms per token, 35482.40 tokens per second)
llama_perf_context_print:        load time =    1111.98 ms
llama_perf_context_print: prompt eval time =     167.49 ms /    11 tokens (   15.23 ms per token,    65.67 tokens per second)
llama_perf_context_print:        eval time =   14361.70 ms /   376 runs   (   38.20 ms per token,    26.18 tokens per second)
llama_perf_context_print:       total time =   14553.14 ms /   387 tokens
</code></pre><h4 id="thread-count-16">Thread count: 16</h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># High thread count (16 threads, for powerful systems)</span>
</span></span><span style="display:flex;"><span>./build/bin/llama-cli -m models/mistral-7b-v0.1.Q4_K_M.gguf -t <span style="color:#ae81ff">16</span> -p <span style="color:#e6db74">&#34;Write a short story about a robot learning to paint&#34;</span>
</span></span></code></pre></div><p>Output:</p>
<pre tabindex="0"><code> Write a short story about a robot learning to paint.

Once upon a time, in a world not so different from our own, there was a robot named Robby. Robby was designed to help people with their daily tasks, making their lives easier and more efficient. However, Robby had always been curious about art. He had seen humans create beautiful paintings and had always been fascinated by the process.

One day, Robby decided that he wanted to learn how to paint. He asked his human owner if it would be possible, and his owner smiled and said, &#34;Of course, Robby. I&#39;ll help you get started.&#34;

Robby&#39;s owner took him to an art store and bought him some brushes, paints, and a canvas. Robby was so excited to start that he couldn&#39;t wait to get home.

When Robby got home, he sat down in front of his canvas and started to paint. At first, he struggled. He didn&#39;t know which colors to use or how to mix them. He didn&#39;t know how to hold his brush or how to move it across the canvas.

But Robby was determined. He kept trying, and with each stroke, he got better. He started to experiment with different colors and techniques, and soon he was creating beautiful paintings.

Robby was so proud of himself. He had never thought that he would be able to create art, but he had done it. He had learned to paint, and he had discovered a new passion in life.

From that day forward, Robby continued to paint. He created beautiful paintings that were admired by all who saw them. He had found a new way to express himself and to create something beautiful.

Robby had learned that even though he was a robot, he was capable of great things. He had learned that with determination and hard work, he could achieve anything he set his mind to. And he had learned that art was a wonderful way to express creativity and passion. [end of text]


llama_perf_sampler_print:    sampling time =      12.17 ms /   424 runs   (    0.03 ms per token, 34831.18 tokens per second)
llama_perf_context_print:        load time =    3077.19 ms
llama_perf_context_print: prompt eval time =     161.56 ms /    11 tokens (   14.69 ms per token,    68.09 tokens per second)
llama_perf_context_print:        eval time =   15955.79 ms /   412 runs   (   38.73 ms per token,    25.82 tokens per second)
llama_perf_context_print:       total time =   16146.24 ms /   423 tokens
</code></pre><ul>
<li>Note: Performance may vary based on:
<ul>
<li>Hardware specifications</li>
<li>System load</li>
<li>Model size and quantization</li>
<li>Context window size</li>
<li>Available memory</li>
</ul>
</li>
</ul>
<h3 id="3-context-window-size--c">3) Context Window Size (-c)</h3>
<table>
  <thead>
      <tr>
          <th><strong>Context Size</strong></th>
          <th><strong>Token Limit</strong></th>
          <th><strong>Best Used When</strong></th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>Small</strong></td>
          <td>512 tokens</td>
          <td>- Memory is limited<!-- raw HTML omitted -->- For simple queries<!-- raw HTML omitted -->- Response length is short<!-- raw HTML omitted -->- On resource-constrained devices</td>
      </tr>
      <tr>
          <td><strong>Medium</strong></td>
          <td>2048 tokens</td>
          <td>- General purpose use<!-- raw HTML omitted -->- Balanced performance<!-- raw HTML omitted -->- Most common use cases<!-- raw HTML omitted -->- Standard documentation</td>
      </tr>
      <tr>
          <td><strong>Large</strong></td>
          <td>4096 tokens</td>
          <td>- Complex analysis<!-- raw HTML omitted -->- Long-form content<!-- raw HTML omitted -->- Research papers<!-- raw HTML omitted -->- Detailed documentation<!-- raw HTML omitted -->- Context retention is crucial</td>
      </tr>
  </tbody>
</table>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># Small context (512 tokens)</span>
</span></span><span style="display:flex;"><span>./build/bin/llama-cli -m models/mistral-7b-v0.1.Q4_K_M.gguf -c <span style="color:#ae81ff">512</span> -p <span style="color:#e6db74">&#34;Write a detailed analysis of climate change impacts on coastal cities&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Medium context (2048 tokens, recommended)</span>
</span></span><span style="display:flex;"><span>./build/bin/llama-cli -m models/mistral-7b-v0.1.Q4_K_M.gguf -c <span style="color:#ae81ff">2048</span> -p <span style="color:#e6db74">&#34;Write a detailed analysis of climate change impacts on coastal cities&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Large context (4096 tokens)</span>
</span></span><span style="display:flex;"><span>./build/bin/llama-cli -m models/mistral-7b-v0.1.Q4_K_M.gguf -c <span style="color:#ae81ff">4096</span> -p <span style="color:#e6db74">&#34;Write a detailed analysis of climate change impacts on coastal cities&#34;</span>
</span></span></code></pre></div><p>Example Outputs:</p>
<ol>
<li>Small Context (512 tokens):</li>
</ol>
<pre tabindex="0"><code>Climate change significantly impacts coastal cities through rising sea levels, increased flooding, and more frequent extreme weather events. These changes threaten infrastructure, displace populations, and damage ecosystems. Adaptation measures like sea walls and improved drainage systems are essential for urban resilience.
</code></pre><ol start="2">
<li>Medium Context (2048 tokens):</li>
</ol>
<pre tabindex="0"><code>Climate change poses significant challenges to coastal cities worldwide. Rising sea levels, increased flooding, and more frequent extreme weather events threaten urban infrastructure and populations. Key impacts include:

1. Infrastructure Damage:
- Flooding of critical systems
- Erosion of coastal structures
- Damage to transportation networks

2. Population Displacement:
- Forced migration from low-lying areas
- Increased housing insecurity
- Social and economic disruption

3. Environmental Changes:
- Saltwater intrusion
- Ecosystem degradation
- Loss of biodiversity

Adaptation strategies include:
- Building sea walls and flood barriers
- Implementing improved drainage systems
- Developing early warning systems
- Creating climate-resilient urban planning
</code></pre><ul>
<li>Memory Usage: ~2GB RAM</li>
<li>Generation Speed: ~40 tokens/second</li>
<li>Best for: Most general use cases, balanced performance</li>
</ul>
<ol start="3">
<li>Large Context (4096 tokens):</li>
</ol>
<pre tabindex="0"><code>Climate change presents complex challenges for coastal cities, requiring comprehensive analysis of multiple interconnected factors:

1. Direct Environmental Impacts:
- Rising sea levels (projected 0.5-1.2m by 2100)
- Increased frequency of extreme weather events
- Ocean acidification affecting marine ecosystems
- Changes in precipitation patterns

2. Infrastructure Vulnerabilities:
- Critical systems at risk:
  * Power generation and distribution
  * Water treatment facilities
  * Transportation networks
  * Communication systems
- Economic costs of damage and repair
- Insurance implications

3. Social and Economic Consequences:
- Population displacement and migration
- Housing market disruptions
- Public health challenges
- Economic productivity impacts
- Cultural heritage preservation

4. Adaptation Strategies:
- Engineering solutions:
  * Sea walls and flood barriers
  * Elevated infrastructure
  * Improved drainage systems
- Policy measures:
  * Zoning regulations
  * Building codes
  * Emergency response plans
- Community engagement:
  * Public awareness programs
  * Stakeholder participation
  * Education initiatives

5. Long-term Planning Considerations:
- Climate modeling and prediction
- Risk assessment methodologies
- Cost-benefit analysis
- Sustainable development goals
</code></pre><h3 id="3-temperature-temp">3) Temperature (&ndash;temp)</h3>
<p>The temperature parameter affects the probability distribution of the next token. Lower temperatures make the distribution more peaked (focused on the most likely tokens), while higher temperatures make it more uniform (allowing less likely tokens to be selected). The actual outputs may vary between runs, and the optimal temperature setting depends on your specific use case.</p>
<table>
  <thead>
      <tr>
          <th><strong>Temperature Level</strong></th>
          <th><strong>Range</strong></th>
          <th><strong>Best Used When</strong></th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>Low Temperature</strong></td>
          <td>0.1 - 0.3</td>
          <td>- Accuracy is crucial<!-- raw HTML omitted -->- For technical content<!-- raw HTML omitted -->- Consistency is important<!-- raw HTML omitted -->- Code generation<!-- raw HTML omitted -->- Working with facts</td>
      </tr>
      <tr>
          <td><strong>Medium Temperature</strong></td>
          <td>0.4 - 0.8</td>
          <td>- General purpose use<!-- raw HTML omitted -->- Balanced creativity<!-- raw HTML omitted -->- Most common use cases<!-- raw HTML omitted -->- Natural language<!-- raw HTML omitted -->- Blog posts and articles</td>
      </tr>
      <tr>
          <td><strong>High Temperature</strong></td>
          <td>0.9 - 1.2</td>
          <td>- Creative writing<!-- raw HTML omitted -->- Poetry and fiction<!-- raw HTML omitted -->- Brainstorming sessions<!-- raw HTML omitted -->- Unique outputs<!-- raw HTML omitted -->- Artistic content</td>
      </tr>
  </tbody>
</table>
<p>Below are some examples of the same prompt with different temprature values.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># Low temperature (0.1) - More focused, deterministic</span>
</span></span><span style="display:flex;"><span>./build/bin/llama-cli -m models/mistral-7b-v0.1.Q4_K_M.gguf --temp 0.1 -p <span style="color:#e6db74">&#34;Write a poem about the ocean&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Medium temperature (0.8) - Balanced creativity</span>
</span></span><span style="display:flex;"><span>./build/bin/llama-cli -m models/mistral-7b-v0.1.Q4_K_M.gguf --temp 0.8 -p <span style="color:#e6db74">&#34;Write a poem about the ocean&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># High temperature (1.2) - More creative, diverse</span>
</span></span><span style="display:flex;"><span>./build/bin/llama-cli -m models/mistral-7b-v0.1.Q4_K_M.gguf --temp 1.2 -p <span style="color:#e6db74">&#34;Write a poem about the ocean&#34;</span>
</span></span></code></pre></div><p>Example Outputs:</p>
<ol>
<li>Low Temperature (0.1):</li>
</ol>
<pre tabindex="0"><code>The ocean vast and deep,
A world of secrets to keep.
Waves dance in the light,
As day turns to night.
</code></pre><ol start="2">
<li>Medium Temperature (0.8):</li>
</ol>
<pre tabindex="0"><code>Beneath the azure sky so wide,
The ocean&#39;s secrets gently hide.
Waves whisper ancient tales untold,
Of treasures deep and mysteries bold.
The sun&#39;s reflection dances bright,
As dolphins leap in pure delight.
</code></pre><ol start="3">
<li>High Temperature (1.2):</li>
</ol>
<pre tabindex="0"><code>Oh, mighty ocean, wild and free,
Your depths hold more than eyes can see.
Mermaids sing in coral halls,
While whales dance in watery balls.
The moon pulls tides like puppet strings,
As seagulls spread their silver wings.
In your embrace, both life and death,
Each wave a story, every breath.
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Working with llama.cpp Locally</title>
            <link>/posts/2025/05/working-with-llama.cpp-locally/</link>
            <pubDate>Mon, 05 May 2025 00:00:00 +0000</pubDate>
            
            <guid>/posts/2025/05/working-with-llama.cpp-locally/</guid>
            <description>&lt;h3 id=&#34;introduction&#34;&gt;Introduction&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/ggml-org/llama.cpp&#34;&gt;llama.cpp&lt;/a&gt; is a powerful C++ implementation of the LLaMA model that allows you to run large language models locally on your machine. This guide will walk you through the process of setting up and using llama.cpp effectively. Official github repo has enough details, however I have still more granular steps here and sample outputs.&lt;/p&gt;
&lt;h3 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;C++ compiler (GCC or Clang)&lt;/li&gt;
&lt;li&gt;CMake&lt;/li&gt;
&lt;li&gt;Git&lt;/li&gt;
&lt;li&gt;Sufficient disk space for model weights&lt;/li&gt;
&lt;li&gt;Adequate RAM (8GB minimum recommended)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;installation-steps&#34;&gt;Installation Steps&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Clone the repository:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;git clone https://github.com/ggerganov/llama.cpp.git
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cd llama.cpp
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Build the project:&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mkdir build
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cd build
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cmake ..
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;cmake --build . --config Release
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;downloading-models&#34;&gt;Downloading Models&lt;/h3&gt;
&lt;p&gt;You can download various LLaMA models from Hugging Face. Here are multiple methods:&lt;/p&gt;</description>
            <content type="html"><![CDATA[<h3 id="introduction">Introduction</h3>
<p><a href="https://github.com/ggml-org/llama.cpp">llama.cpp</a> is a powerful C++ implementation of the LLaMA model that allows you to run large language models locally on your machine. This guide will walk you through the process of setting up and using llama.cpp effectively. Official github repo has enough details, however I have still more granular steps here and sample outputs.</p>
<h3 id="prerequisites">Prerequisites</h3>
<ul>
<li>C++ compiler (GCC or Clang)</li>
<li>CMake</li>
<li>Git</li>
<li>Sufficient disk space for model weights</li>
<li>Adequate RAM (8GB minimum recommended)</li>
</ul>
<h3 id="installation-steps">Installation Steps</h3>
<ol>
<li>Clone the repository:</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>git clone https://github.com/ggerganov/llama.cpp.git
</span></span><span style="display:flex;"><span>cd llama.cpp
</span></span></code></pre></div><ol start="2">
<li>Build the project:</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>mkdir build
</span></span><span style="display:flex;"><span>cd build
</span></span><span style="display:flex;"><span>cmake ..
</span></span><span style="display:flex;"><span>cmake --build . --config Release
</span></span></code></pre></div><h3 id="downloading-models">Downloading Models</h3>
<p>You can download various LLaMA models from Hugging Face. Here are multiple methods:</p>
<ol>
<li>Using wget (recommended for simplicity):</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># Create a models directory</span>
</span></span><span style="display:flex;"><span>mkdir -p models
</span></span><span style="display:flex;"><span>cd models
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Download Mistral-7B</span>
</span></span><span style="display:flex;"><span>wget https://huggingface.co/TheBloke/Mistral-7B-v0.1-GGUF/resolve/main/mistral-7b-v0.1.Q4_K_M.gguf
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Download Llama-2-7B</span>
</span></span><span style="display:flex;"><span>wget https://huggingface.co/TheBloke/Llama-2-7B-GGUF/resolve/main/llama2-7b.Q4_K_M.gguf
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Download Phi-2</span>
</span></span><span style="display:flex;"><span>wget https://huggingface.co/TheBloke/phi-2-GGUF/resolve/main/phi-2.Q4_K_M.gguf
</span></span></code></pre></div><ol start="2">
<li>Using curl:</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># Create a models directory</span>
</span></span><span style="display:flex;"><span>mkdir -p models
</span></span><span style="display:flex;"><span>cd models
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Download Mistral-7B</span>
</span></span><span style="display:flex;"><span>curl -L https://huggingface.co/TheBloke/Mistral-7B-v0.1-GGUF/resolve/main/mistral-7b-v0.1.Q4_K_M.gguf -o mistral-7b-v0.1.Q4_K_M.gguf
</span></span></code></pre></div><ol start="3">
<li>Using Python (if you prefer):</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>pip install huggingface_hub
</span></span><span style="display:flex;"><span>huggingface-cli download TheBloke/Mistral-7B-v0.1-GGUF mistral-7b-v0.1.Q4_K_M.gguf --local-dir ./models
</span></span></code></pre></div><p>Popular model options and their sizes:</p>
<ul>
<li>Llama-2-7b (4-bit quantized): ~4GB</li>
<li>Llama-2-13b (4-bit quantized): ~7GB</li>
<li>Mistral-7B (4-bit quantized): ~4GB</li>
<li>Phi-2 (4-bit quantized): ~2GB</li>
</ul>
<p>Note: The <code>Q4_K_M</code> suffix indicates 4-bit quantization, which provides a good balance between model size and performance. Other quantization levels are available (Q2_K, Q5_K, Q8_0) depending on your needs for quality vs. size.</p>
<h3 id="running-inference">Running Inference</h3>
<h4 id="mode-1-single-shot-with-inline-prompt">Mode 1: Single shot with inline prompt</h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>cd /Users/hpjoshi/Documents/AppliedAI/llama.cpp <span style="color:#f92672">&amp;&amp;</span> ./build/bin/llama-cli -m /Users/hpjoshi/Documents/AppliedAI/llm/models/mistral-q4.gguf -p <span style="color:#e6db74">&#34;write a simple HTML and CSS code to create a bouncing ball animation using jQuery&#34;</span>
</span></span></code></pre></div><p>The command structure is:</p>
<ul>
<li><code>./build/bin/llama-cli</code>: The compiled executable</li>
<li><code>-m</code>: Path to your model file (typically a .gguf file)</li>
<li><code>-p</code>: Your prompt or input text</li>
</ul>
<p>Common model paths:</p>
<ul>
<li>Local models: <code>../llm/models/your-model.gguf</code></li>
<li>Absolute path: <code>/path/to/your/model.gguf</code></li>
</ul>
<p>You can also add additional parameters:</p>
<ul>
<li><code>-n</code>: Number of tokens to generate</li>
<li><code>-t</code>: Number of threads to use</li>
<li><code>-c</code>: Context window size</li>
</ul>
<h3 id="sample-outputs">Sample Outputs</h3>
<p>Here are some example outputs from different prompts using Mistral-7B:</p>
<ol>
<li>Joke Generation:</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>./build/bin/llama-cli -m ../llm/models/mistral-q4.gguf -p <span style="color:#e6db74">&#34;tell me a joke&#34;</span>
</span></span></code></pre></div><p>Output:</p>
<pre tabindex="0"><code>Why don&#39;t scientists trust atoms?
Because they make up everything!
</code></pre><ol start="2">
<li>Code Generation:</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>./build/bin/llama-cli -m ../llm/models/mistral-q4.gguf -p <span style="color:#e6db74">&#34;write a python function to calculate fibonacci numbers&#34;</span>
</span></span></code></pre></div><p>Output:</p>
<pre tabindex="0"><code> write a python function to calculate fibonacci numbers using recursion
function fibonacci(n):
    if n &lt;= 1:
        return n
    else:
        return(fibonacci(n-1) + fibonacci(n-2))

# test the function
print(fibonacci(8)) # 21 [end of text]
</code></pre><ol start="3">
<li>Question Answering:</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>./build/bin/llama-cli -m ../llm/models/mistral-q4.gguf -p <span style="color:#e6db74">&#34;What is the capital of France?&#34;</span>
</span></span></code></pre></div><p>Output:</p>
<pre tabindex="0"><code>The capital of France is Paris. It is the largest city in France and serves as the country&#39;s political, economic, and cultural center.
</code></pre><p>Note: The actual outputs may vary slightly between runs and different model versions. The quality of responses depends on the model size, quantization level, and the specific prompt used.</p>
<h4 id="mode-2-chat-mode">Mode 2: Chat mode</h4>
<p>With below command, you can run any model locally. This run locally on specifided port using OpenAPI.</p>
<pre tabindex="0"><code>./build/bin/llama-server -m ../llm/models/mistral-q4.gguf
</code></pre><p>This is how sample chat-mode UI looks.</p>
<p><img src="/images/llama-cpp-chat-mode.png" alt="Model Loading"></p>
<h3 id="some-more-examples">Some more examples</h3>
<p>Here are some examples of llama.cpp in action:</p>
<ol>
<li>
<p>Model Loading Process:
<img src="/images/llama-cpp-loading.png" alt="Model Loading">
<em>The model loading process showing Metal GPU initialization and model metadata</em></p>
</li>
<li>
<p>Code Generation Example:
<img src="/images/llama-cpp-code.png" alt="Code Generation">
<em>Example of code generation showing a complete HTML/CSS/JS solution for a bouncing ball animation</em></p>
</li>
<li>
<p>Interactive Response Example:
<img src="/images/llama-cpp-travel.png" alt="Interactive Response">
<em>Example of a detailed, structured response to a travel-related question</em></p>
</li>
</ol>
<p>Note: The actual outputs may vary slightly between runs and different model versions. The quality of responses depends on the model size, quantization level, and the specific prompt used.</p>
<h3 id="conclusion">Conclusion</h3>
<p>llama.cpp provides a powerful way to run large language models locally, giving you full control over your AI applications while maintaining privacy and reducing costs. The flexibility in model selection, quantization options, and performance tuning makes it an excellent choice for both development and production use cases.</p>
<blockquote>
<p>Next in the series: <a href="/posts/2025/05/diving-deep-on-model-optimization-parameters-using-llama.cpp/">Diving Deep into model parameters with llama.cpp</a></p></blockquote>
]]></content>
        </item>
        
    </channel>
</rss>
